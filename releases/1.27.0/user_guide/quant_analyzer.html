<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AIMET QuantAnalyzer &mdash; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.27.0</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            AI Model Efficiency Toolkit
              <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                tf-torch-cpu_1.27.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="model_quantization.html">Quantization User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_quantization.html#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_quantization.html#aimet-quantization-features">AIMET Quantization Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_quantization.html#aimet-quantization-workflow">AIMET Quantization Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_quantization.html#debugging-guidelines">Debugging Guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_compression.html">Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#winnowing">Winnowing</a></li>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_docs/index.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/torch.html">AIMET APIs for PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_quantization.html">PyTorch Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#tar-selection-parameters">TAR Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#configuration-definitions">Configuration Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#enum-definition">Enum Definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/tensorflow.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_model_guidelines.html">TensorFlow Model Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_quantization.html">TensorFlow Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_compress.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#configuration-definitions">Configuration Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#code-examples">Code Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#weight-svd-top-level-api">Weight SVD Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#code-examples-for-weight-svd">Code Examples for Weight SVD</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_visualization_quantization.html">TensorFlow Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_visualization_quantization.html#top-level-api-for-visualization-of-weight-tensors">Top-level API for Visualization of Weight tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_visualization_quantization.html#code-examples-for-visualization-of-weight-tensors">Code Examples for Visualization of Weight tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html">Using AIMET Tensorflow APIs with Keras Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#apis">APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#code-example">Code Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#utility-functions">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_layer_output_generation.html">Tensorflow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/keras.html">AIMET APIs for Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/keras_quantization.html">Keras Model Quantization API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/onnx_quantization.html">ONNX Model Quantization API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#release-packages">Release packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#installation-instructions">Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-pytorch-or-onnx">Install GPU packages for PyTorch or ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-tensorflow">Install GPU packages for TensorFlow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-aimet-packages">Install AIMET packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#install-aimet-packages">Install AIMET packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">AIMET QuantAnalyzer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/quant_analyzer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="aimet-quantanalyzer">
<span id="ug-quant-analyzer"></span><h1>AIMET QuantAnalyzer<a class="headerlink" href="#aimet-quantanalyzer" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>The QuantAnalyzer feature analyzes the model for quantization and points out sensitive parts/hotspots in the model.
The analyses are performed automatically, and only requires the user to pass in callbacks for performing forward pass and evaluation, and optionally a dataloader for MSE loss analysis.</p>
<p>For each analysis, QuantAnalyzer outputs json and/or html files containing data and plots for easy visualization.</p>
</div>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<dl class="simple">
<dt>To call the QuantAnalyzer API, users need to provide the following:</dt><dd><ul class="simple">
<li><p>An FP32 pretrained model for analysis</p></li>
<li><p>A dummy input for the model which can contain random values, but must match the shape of the model’s expected input</p></li>
<li><p>A user defined function for passing 500-1000 representative data samples through the model for quantization calibration.</p></li>
<li><p>A user defined function for passing labeled data through the model for evaluation, returning an accuracy metric</p></li>
<li><p>(Optional, for runing MSE loss analysis) A dataloader providing unlabeled data to be passed through the model</p></li>
</ul>
</dd>
</dl>
<p>Other quantization related settings are also provided in the call to analyze a model.
Please refer to <a class="reference internal" href="../api_docs/torch_quant_analyzer.html"><span class="doc">PyTorch QuantAnalyzer API Docs</span></a> for more information on how to call the QuantAnalyzer feature.</p>
<p><strong>Note</strong>: Typically on quantized runtimes, batch normalization layers will be folded where possible.
So that users do not have to call a separate API to do so, QuantAnalyzer automatically performs Batch Norm Folding prior to running its analyses.</p>
</div>
<div class="section" id="detailed-analysis-descriptions">
<h2>Detailed Analysis Descriptions<a class="headerlink" href="#detailed-analysis-descriptions" title="Permalink to this headline">¶</a></h2>
<p>QuantAnalyzer performs the following analyses:</p>
<ol class="arabic">
<li><dl>
<dt>Sensitivity analysis to weight and activation quantization:</dt><dd><p>QuantAnalyzer compares the accuracies of the original FP32 model, an activation-only quantized model, and a weight-only quantized model.</p>
<p>This helps users determine which AIMET quantization technique(s) will be more beneficial for the model.
For example, in situations where the model is more sensitive to activation quantization, PTQ techniques like Adaptive Rounding or Cross Layer Equalization might not be very helpful.</p>
<p>Accuracy values for each model are printed as part of AIMET logging.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Per layer quantizer enablement analysis:</dt><dd><p>Sometimes the accuracy drop incurred from quantization can be attributed to only a subset of quantizers within the model.
QuantAnalyzer performs analyses to find such layers by enabling and disabling individual quantizers to observe how the model accuracy changes.</p>
<p>The following two types of quantizer enablement analyses are performed:</p>
<ol class="arabic simple">
<li><p>Disable all quantizers across the model and, for each layer, enable only that layer’s output quantizer and perform evaluation with the provided callback.
This results in accuracy values obtained for each layer in the model when only that layer’s quantizer is enabled, allowing users to observe effects of individual layer quantization and pinpoint culprit layer(s) and hotspots.</p></li>
<li><p>Enable all quantizers across the model and, for each layer, disable only that layer’s output quantizer and perform evaluation with the provided callback.
Once again, accuracy values are produced for each layer in the model when only that layer’s quantizer is disabled.</p></li>
</ol>
<p>As a result of these analyses, AIMET outputs per_layer_quant_enabled.html and per_layer_quant_disabled.html respectively, containing plots mapping layers on the x-axis to model accuracy on the y-axis.</p>
<p>JSON files per_layer_quant_enabled.json and per_layer_quant_disabled.json are also produced, containing the data shown in the .html plots.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Per layer encodings min-max range analysis:</dt><dd><p>As part of quantization, encoding parameters for each quantizer must be obtained.
These parameters include scale, offset, min, and max, and are used for mapping floating point values to quantized integer values.</p>
<p>QuantAnalyzer tracks the min and max encoding parameters computed by each quantizer in the model as a result of forward passes through the model with representative data (from which the scale and offset values can be directly obtained).</p>
<p>As a result of this analysis, AIMET outputs html plots and json files for each activation quantizer and each parameter quantizer (contained in the min_max_ranges folder), containing the encoding min/max values for each.</p>
<p>If Per Channel Quantization (PCQ) is enabled, encoding min and max values for all the channels of each weight will be shown.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Per layer statistics histogram:</dt><dd><p>Under the TF Enhanced quantization scheme, encoding min/max values for each quantizer are obtained by collecting a histogram of tensor values seen at that quantizer and potentially tossing out outliers.</p>
<p>When this quantization scheme is selected, QuantAnalyzer will output plots for each quantizer in the model, displaying the histogram of tensor values seen at that quantizer.
These plots are available as part of the activations_pdf and weights_pdf folders, containing a separate .html plot for each quantizer.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Per layer MSE loss:</dt><dd><p>An optional analysis QuantAnalyzer can do is to monitor each layer’s output in the original FP32 model as well as the corresponding layer output in the quantized model, and calculate the MSE loss between the two.
This helps identify which layers may contribute more to quantization noise.</p>
<p>To enable this optional analysis, users need to pass in a dataloader for QuantAnalyzer to read from.
Approximately 256 samples/images are sufficient.</p>
<p>A per_layer_mse_loss.html file will be generated containing a plot mapping layer quantizers on the x-axis to MSE loss on the y-axis.
A corresponding per_layer_mse_loss.json file will also be generated containing data corresponding to the .html file.</p>
</dd>
</dl>
</li>
</ol>
</div>
</div>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>