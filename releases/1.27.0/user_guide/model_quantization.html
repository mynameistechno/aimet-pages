<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AIMET Model Quantization &mdash; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.27.0</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="AIMET Model Compression" href="model_compression.html" />
    <link rel="prev" title="AI Model Efficiency Toolkit User Guide" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            AI Model Efficiency Toolkit
              <img src="../_static/brain_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                tf-torch-cpu_1.27.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quantization User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="#aimet-quantization-features">AIMET Quantization Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#aimet-quantization-workflow">AIMET Quantization Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#debugging-guidelines">Debugging Guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="model_compression.html">Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#winnowing">Winnowing</a></li>
<li class="toctree-l4"><a class="reference internal" href="channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_docs/index.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/torch.html">AIMET APIs for PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_quantization.html">PyTorch Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#tar-selection-parameters">TAR Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#configuration-definitions">Configuration Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#enum-definition">Enum Definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/tensorflow.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_model_guidelines.html">TensorFlow Model Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_quantization.html">TensorFlow Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_compress.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#configuration-definitions">Configuration Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#code-examples">Code Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#weight-svd-top-level-api">Weight SVD Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_compress.html#code-examples-for-weight-svd">Code Examples for Weight SVD</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_visualization_quantization.html">TensorFlow Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_visualization_quantization.html#top-level-api-for-visualization-of-weight-tensors">Top-level API for Visualization of Weight tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_visualization_quantization.html#code-examples-for-visualization-of-weight-tensors">Code Examples for Visualization of Weight tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html">Using AIMET Tensorflow APIs with Keras Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#apis">APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#code-example">Code Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/convert_tf_sess_to_keras.html#utility-functions">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/tensorflow_layer_output_generation.html">Tensorflow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api_docs/tensorflow_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/keras.html">AIMET APIs for Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/keras_quantization.html">Keras Model Quantization API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../api_docs/onnx_quantization.html">ONNX Model Quantization API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api_docs/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#release-packages">Release packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../install/index.html#installation-instructions">Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-pytorch-or-onnx">Install GPU packages for PyTorch or ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-gpu-packages-for-tensorflow">Install GPU packages for TensorFlow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-aimet-packages">Install AIMET packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#install-aimet-packages">Install AIMET packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">AIMET Model Quantization</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/user_guide/model_quantization.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="index.html" class="btn btn-neutral float-left" title="AI Model Efficiency Toolkit User Guide" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_compression.html" class="btn btn-neutral float-right" title="AIMET Model Compression" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="aimet-model-quantization">
<span id="ug-model-quantization"></span><h1>AIMET Model Quantization<a class="headerlink" href="#aimet-model-quantization" title="Permalink to this headline">¶</a></h1>
<p>Models are generally trained on floating-point hardware like CPUs and GPUs. However, when these trained models are run
on quantized hardware that support fixed-precision operations, model parameters are converted from floating-point
precision to fixed precision. As an example, when running on hardware that supports 8-bit integer operations, the
floating point parameters in the trained model need to be converted to 8-bit integers. It is observed that for some
models, running on an 8-bit fixed-precision runtime introduces a loss in accuracy due to noise added from the use
of fixed precision parameters and fixed precision operations.</p>
<p>AIMET provides multiple techniques and tools which help to create quantized models with a minimal loss in accuracy
relative to floating-point models.</p>
<p>This section provides information on typical use cases and AIMET’s quantization features.</p>
<div class="section" id="use-cases">
<h2>Use Cases<a class="headerlink" href="#use-cases" title="Permalink to this headline">¶</a></h2>
<p>1. <strong>Predict on-target accuracy</strong>: AIMET enables a user to simulate the effects of quantization to get a first order
estimate of the model’s accuracy when run on quantized targets. This is useful to get an estimate of on-target accuracy
without needing an actual target platform. Note that to create a simulation model, AIMET uses representative data
samples to compute per-layer quantization encodings.</p>
<blockquote>
<div><img alt="../_images/quant_use_case_1.PNG" src="../_images/quant_use_case_1.PNG" />
</div></blockquote>
<p>2. <strong>Post-Training Quantization (PTQ)</strong>: PTQ techniques attempt to make a model more quantization friendly without
requiring model re-training/fine-tuning. PTQ (as opposed to fine-tuning) is recommended as a first step in a
quantization workflow due to the following advantages:</p>
<ul>
<li><p>No need for the original training pipeline; an evaluation pipeline is sufficient</p></li>
<li><p>Only requires a small unlabeled dataset for calibration (can even be data-free in some scenarios)</p></li>
<li><p>Fast, simple, and easy to use</p>
<blockquote>
<div><img alt="../_images/quant_use_case_3.PNG" src="../_images/quant_use_case_3.PNG" />
</div></blockquote>
</li>
</ul>
<p>Note that with PTQ techniques, the quantized model accuracy may still have a gap relative to the floating-point model.
In such a scenario, or to even further improve the model accuracy, fine-tuning is recommended.</p>
<p>3. <strong>Quantization-Aware Training (QAT)/Fine-Tuning</strong>: QAT enables a user to fine-tune a model with quantization
operations inserted in network graph, which in effect adapts the model parameters to be robust to quantization noise.
While QAT requires access to a training pipeline and dataset, and takes longer to run due to needing a few epochs of
fine-tuning, it can provide better accuracy especially at low bitwidths. A typical QAT workflow is illustrated below.</p>
<blockquote>
<div><img alt="../_images/quant_use_case_2.PNG" src="../_images/quant_use_case_2.PNG" />
</div></blockquote>
</div>
<div class="section" id="aimet-quantization-features">
<h2>AIMET Quantization Features<a class="headerlink" href="#aimet-quantization-features" title="Permalink to this headline">¶</a></h2>
<ul>
<li><dl class="simple">
<dt><a class="reference internal" href="quantization_sim.html"><span class="doc">Quantization Simulation</span></a>:</dt><dd><p>QuantSim enables a user to modify a model by adding quantization simulation ops. When an evaluation is run on a
model with these quantization simulation ops, the user can observe a first-order simulation of expected accuracy on
quantized hardware.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Post-Training Quantization (PTQ) Techniques</dt><dd><p>Post-training quantization techniques help a model improve quantized accuracy without needing to re-train.</p>
<ul class="simple">
<li><dl class="simple">
<dt><a class="reference internal" href="auto_quant.html#ug-auto-quant"><span class="std std-ref">AutoQuant</span></a>:</dt><dd><p>AIMET provides an API that integrates the post-training quantization techniques described below. AutoQuant is
recommended for PTQ. If desired, individual techniques can be invoked using standalone feature specific APIs.</p>
<ul>
<li><dl class="simple">
<dt><a class="reference internal" href="adaround.html#ug-adaround"><span class="std std-ref">Adaptive Rounding (AdaRound)</span></a>:</dt><dd><p>Determines optimal rounding for weight tensors to improve quantized performance.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference internal" href="post_training_quant_techniques.html#ug-post-training-quantization"><span class="std std-ref">Cross-Layer Equalization</span></a>:</dt><dd><p>Equalizes weight ranges in consecutive layers.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference internal" href="bn_reestimation.html#ug-bn-reestimation"><span class="std std-ref">BN Re-estimation</span></a>:</dt><dd><p>Re-estimates Batch Norm layer statistics before folding the Batch Norm layers.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference internal" href="post_training_quant_techniques.html#ug-post-training-quantization"><span class="std std-ref">Bias Correction</span></a> [Deprecated]:</dt><dd><p>Bias Correction is considered deprecated. It is advised to use AdaRound instead.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><a class="reference internal" href="quantization_aware_training.html#ug-quantization-aware-training"><span class="std std-ref">Quantization-Aware Training (QAT)</span></a>:</dt><dd><p>QAT allows users to take a QuantSim model and further fine-tune the model parameters by taking quantization into
account.</p>
<p>Two modes of QAT are supported:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Regular QAT:</dt><dd><p>Fine-tuning of model parameters. Trainable parameters such as module weights, biases, etc. can be
updated. The scale and offset quantization parameters for activation quantizers remain constant. Scale and
offset parameters for weight quantizers will update to reflect new weight values after each training step.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>QAT with Range Learning:</dt><dd><p>In addition to trainable module weights and scale/offset parameters for weight quantizers, scale/offset
parameters for activation quantizers are also updated during each training step.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Debugging/Analysis Tools</dt><dd><ul class="simple">
<li><dl class="simple">
<dt><a class="reference internal" href="quant_analyzer.html#ug-quant-analyzer"><span class="std std-ref">QuantAnalyzer</span></a>:</dt><dd><p>Automated debugging of the model to understand sensitivity to weight and/or activation quantization, individual
layer sensitivity, etc.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><a class="reference internal" href="visualization_quant.html#ug-quantization-visualization"><span class="std std-ref">Visualizations</span></a>:</dt><dd><p>Visualizations and histograms of weight and activation ranges.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="aimet-quantization-workflow">
<h2>AIMET Quantization Workflow<a class="headerlink" href="#aimet-quantization-workflow" title="Permalink to this headline">¶</a></h2>
<p>This section describes the recommended workflow for quantizing a neural network.</p>
<blockquote>
<div><img alt="../_images/quantization_workflow.PNG" src="../_images/quantization_workflow.PNG" />
</div></blockquote>
<p><strong>1. Model prep and validation</strong></p>
<p>Before attempting quantization, ensure that models have been defined in accordance to model guidelines. These guidelines
depend on the ML framework the model is written in.</p>
<dl>
<dt>Pytorch:</dt><dd><p><a class="reference internal" href="../api_docs/torch_model_guidelines.html"><span class="doc">PyTorch Model Guidelines</span></a></p>
<p>In the case of PyTorch, there exists the Model Validator utility, to automate the checking of certain PyTorch model
requirements, as well as the Model Preparer utility, to automate the updating of the model definition to align with
certain requirements.</p>
<p>In this model prep and validation phase, we advise the following flow:</p>
<img alt="../_images/pytorch_model_prep_and_validate.PNG" src="../_images/pytorch_model_prep_and_validate.PNG" />
<p>Users can use the model validator utility first to check if the model can be run with AIMET. If validator checks
fail, users can first try using model preparer in their pipeline, an automated feature for updating models, and
retry the model validator to see if checks now pass. If the validator continues to print warnings, users will need
to update the model definition by hand prior to using AIMET features.</p>
<p>For more information on model validator and preparer, refer to the corresponding sections in
<a class="reference internal" href="../api_docs/torch_quantization.html"><span class="doc">AIMET PyTorch Quantization APIs</span></a>.</p>
</dd>
<dt>Tensorflow:</dt><dd><p><a class="reference internal" href="../api_docs/tensorflow_model_guidelines.html"><span class="doc">TensorFlow Model Guidelines</span></a></p>
</dd>
</dl>
<p><strong>2. PTQ/AutoQuant</strong></p>
<p>The user can apply various PTQ techniques to the model to adjust model parameters and make the model more robust to
quantization. We recommend trying AutoQuant first, a PTQ feature which internally tries various other PTQ methods and
finds the best combination of methods to apply. Refer to the
AIMET Quantization Features section for more details on PTQ/AutoQuant.</p>
<p><strong>3. QAT</strong></p>
<p>If model accuracy is still not satisfactory after PTQ/AutoQuant, the user can use QAT to fine-tune the model. Refer to
the AIMET Quantization Features section for more details on QAT.</p>
<p><strong>4. Exporting models</strong></p>
<p>In order to bring the model onto the target, users will need two things:</p>
<ul class="simple">
<li><p>a model with updated weights</p></li>
<li><p>an encodings file containing quantization parameters associated with each quantization op</p></li>
</ul>
<p>AIMET QuantSim provides export functionality to generate both items. The exported model type will differ based on the ML
framework used:</p>
<ul class="simple">
<li><p>.onnx for PyTorch</p></li>
<li><p>meta/checkpoint for TensorFlow</p></li>
<li><p>.h5 and .pb for Keras</p></li>
</ul>
<p>Depending on which AIMET Quantization features were used, the user may need to take different steps to export the model
and encodings file. For example, calling AutoQuant will automatically export the model and encodings file as part of its
processing. If QAT is used, users will need to call .export() on the QuantSim object. If lower level PTQ techniques like
CLE are used, users will need to first create a QuantSim object from the modified model, and then call .export() on the
QuantSim object.</p>
</div>
<div class="section" id="debugging-guidelines">
<h2>Debugging Guidelines<a class="headerlink" href="#debugging-guidelines" title="Permalink to this headline">¶</a></h2>
<p>Applying AIMET Quantization features may involve some trial and error in order to find the best optimizations to apply
on a particular model. We have included some debugging steps in the <a class="reference internal" href="quantization_feature_guidebook.html#ug-quant-guidebook"><span class="std std-ref">Quantization Guidebook</span></a>
that can be tried when quantization accuracy does not seem to improve right off the bat.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="AI Model Efficiency Toolkit User Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="model_compression.html" class="btn btn-neutral float-right" title="AIMET Model Compression" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>