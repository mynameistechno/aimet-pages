<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>aimet_tensorflow.keras.quantsim &mdash; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.27.0</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../user_guide/index.html" class="icon icon-home">
            AI Model Efficiency Toolkit
              <img src="../../../_static/brain_logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                tf-torch-cpu_1.27.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/model_quantization.html">Quantization User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_quantization.html#use-cases">Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_quantization.html#aimet-quantization-features">AIMET Quantization Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_quantization.html#aimet-quantization-workflow">AIMET Quantization Workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_quantization.html#debugging-guidelines">Debugging Guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/model_compression.html">Compression User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#use-case">Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#compression-ratio-selection">Compression ratio selection</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/visualization_compression.html">Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/visualization_compression.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/visualization_compression.html#design">Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/visualization_compression.html#compression">Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/visualization_compression.html#starting-a-bokeh-server-session">Starting a Bokeh Server Session:</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/visualization_compression.html#how-to-use-the-tool">How to use the tool</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#model-compression">Model Compression</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/weight_svd.html">Weight SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/spatial_svd.html">Spatial SVD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/channel_pruning.html">Channel Pruning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/channel_pruning.html#overall-procedure">Overall Procedure</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/channel_pruning.html#channel-selection">Channel Selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/channel_pruning.html#winnowing">Winnowing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../user_guide/channel_pruning.html#weight-reconstruction">Weight Reconstruction</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#optional-techniques-to-get-better-compression-results">Optional techniques to get better compression results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/model_compression.html#rank-rounding">Rank Rounding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/model_compression.html#per-layer-fine-tuning">Per-layer Fine-tuning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#faqs">FAQs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/model_compression.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_docs/index.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_docs/torch.html">AIMET APIs for PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/torch_quantization.html">PyTorch Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/torch_compress.html">PyTorch Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#tar-selection-parameters">TAR Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#weight-svd-configuration">Weight SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#configuration-definitions">Configuration Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_compress.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/torch_visualization_compression.html">PyTorch Model Visualization API for Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_visualization_compression.html#top-level-api-compression">Top-level API Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_visualization_compression.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/torch_visualization_quantization.html">PyTorch Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_visualization_quantization.html#top-level-api-quantization">Top-level API Quantization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_visualization_quantization.html#code-examples">Code Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/torch_layer_output_generation.html">PyTorch Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_layer_output_generation.html#enum-definition">Enum Definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/torch_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_docs/tensorflow.html">AIMET APIs for TensorFlow</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/tensorflow_model_guidelines.html">TensorFlow Model Guidelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/tensorflow_quantization.html">TensorFlow Model Quantization API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html">TensorFlow Model Compression API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#top-level-api-for-compression">Top-level API for Compression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#greedy-selection-parameters">Greedy Selection Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#spatial-svd-configuration">Spatial SVD Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#channel-pruning-configuration">Channel Pruning Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#configuration-definitions">Configuration Definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#code-examples">Code Examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#weight-svd-top-level-api">Weight SVD Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_compress.html#code-examples-for-weight-svd">Code Examples for Weight SVD</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/tensorflow_visualization_quantization.html">TensorFlow Model Visualization API for Quantization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_visualization_quantization.html#top-level-api-for-visualization-of-weight-tensors">Top-level API for Visualization of Weight tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_visualization_quantization.html#code-examples-for-visualization-of-weight-tensors">Code Examples for Visualization of Weight tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/convert_tf_sess_to_keras.html">Using AIMET Tensorflow APIs with Keras Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/convert_tf_sess_to_keras.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/convert_tf_sess_to_keras.html#apis">APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/convert_tf_sess_to_keras.html#code-example">Code Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/convert_tf_sess_to_keras.html#utility-functions">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/tensorflow_layer_output_generation.html">Tensorflow Debug API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_layer_output_generation.html#top-level-api">Top-level API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_docs/tensorflow_layer_output_generation.html#code-example">Code Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_docs/keras.html">AIMET APIs for Keras</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/keras_quantization.html">Keras Model Quantization API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_docs/onnx.html">AIMET APIs for ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_docs/onnx_quantization.html">ONNX Model Quantization API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_docs/index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide/examples.html">Examples Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/examples.html#browse-the-notebooks">Browse the notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/examples.html#running-the-notebooks">Running the notebooks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/examples.html#install-jupyter">Install Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/examples.html#download-the-example-notebooks-and-related-code">Download the Example notebooks and related code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../user_guide/examples.html#run-the-notebooks">Run the notebooks</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../install/index.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../install/index.html#release-packages">Release packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install/index.html#system-requirements">System Requirements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../install/index.html#installation-instructions">Installation Instructions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../install/install_host.html">Install in Host Machine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-prerequisite-packages">Install prerequisite packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-gpu-packages-for-pytorch-or-onnx">Install GPU packages for PyTorch or ONNX</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-gpu-packages-for-tensorflow">Install GPU packages for TensorFlow</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-aimet-packages">Install AIMET packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-common-debian-packages">Install common debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-tensorflow-gpu-debian-packages">Install tensorflow GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-torch-gpu-debian-packages">Install torch GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#install-onnx-gpu-debian-packages">Install ONNX GPU debian packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#replace-pillow-with-pillow-simd">Replace Pillow with Pillow-SIMD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#replace-onnxruntime-with-onnxruntime-gpu">Replace onnxruntime with onnxruntime-gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#post-installation-steps">Post installation steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_host.html#environment-setup">Environment setup</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../install/install_docker.html">Install in Docker Container</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_docker.html#set-variant">Set variant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_docker.html#use-prebuilt-docker-image">Use prebuilt docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_docker.html#build-docker-image-locally">Build docker image locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_docker.html#start-docker-container">Start docker container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_docker.html#install-aimet-packages">Install AIMET packages</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../install/install_docker.html#environment-setup">Environment setup</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../user_guide/index.html">AI Model Efficiency Toolkit</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../user_guide/index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">aimet_tensorflow.keras.quantsim</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for aimet_tensorflow.keras.quantsim</h1><div class="highlight"><pre>
<span></span><span class="c1"># /usr/bin/env python3.5</span>
<span class="c1"># -*- mode: python -*-</span>
<span class="c1"># =============================================================================</span>
<span class="c1">#  @@-COPYRIGHT-START-@@</span>
<span class="c1">#</span>
<span class="c1">#  Copyright (c) 2022-2023, Qualcomm Innovation Center, Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1">#  Redistribution and use in source and binary forms, with or without</span>
<span class="c1">#  modification, are permitted provided that the following conditions are met:</span>
<span class="c1">#</span>
<span class="c1">#  1. Redistributions of source code must retain the above copyright notice,</span>
<span class="c1">#     this list of conditions and the following disclaimer.</span>
<span class="c1">#</span>
<span class="c1">#  2. Redistributions in binary form must reproduce the above copyright notice,</span>
<span class="c1">#     this list of conditions and the following disclaimer in the documentation</span>
<span class="c1">#     and/or other materials provided with the distribution.</span>
<span class="c1">#</span>
<span class="c1">#  3. Neither the name of the copyright holder nor the names of its contributors</span>
<span class="c1">#     may be used to endorse or promote products derived from this software</span>
<span class="c1">#     without specific prior written permission.</span>
<span class="c1">#</span>
<span class="c1">#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;</span>
<span class="c1">#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE</span>
<span class="c1">#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE</span>
<span class="c1">#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE</span>
<span class="c1">#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR</span>
<span class="c1">#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF</span>
<span class="c1">#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS</span>
<span class="c1">#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN</span>
<span class="c1">#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)</span>
<span class="c1">#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE</span>
<span class="c1">#  POSSIBILITY OF SUCH DAMAGE.</span>
<span class="c1">#</span>
<span class="c1">#  SPDX-License-Identifier: BSD-3-Clause</span>
<span class="c1">#</span>
<span class="c1">#  @@-COPYRIGHT-END-@@</span>
<span class="c1"># =============================================================================</span>
<span class="sd">&quot;&quot;&quot; Quantsim for Keras &quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">aimet_common</span> <span class="kn">import</span> <span class="n">libpymo</span>

<span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantScheme</span><span class="p">,</span> <span class="n">QuantizationDataType</span>
<span class="kn">from</span> <span class="nn">aimet_common.utils</span> <span class="kn">import</span> <span class="n">AimetLogger</span><span class="p">,</span> <span class="n">save_json_yaml</span>
<span class="kn">from</span> <span class="nn">aimet_common.quantsim</span> <span class="kn">import</span> <span class="n">encoding_version</span><span class="p">,</span> <span class="n">extract_global_quantizer_args</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.connectedgraph</span> <span class="kn">import</span> <span class="n">ConnectedGraph</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.graphsearchtuils</span> <span class="kn">import</span> <span class="n">GraphSearchUtils</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.quant_sim.qc_quantize_wrapper</span> <span class="kn">import</span> <span class="n">QcQuantizeWrapper</span><span class="p">,</span> <span class="n">QuantizerSettings</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.quant_sim.qc_mha_wrapper</span> <span class="kn">import</span> <span class="n">QcQuantizableMultiHeadAttention</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.quant_sim.tensor_quantizer</span> <span class="kn">import</span> <span class="n">TensorQuantizer</span><span class="p">,</span> <span class="n">ActivationTensorQuantizer</span><span class="p">,</span> \
    <span class="n">ParamPerTensorQuantizer</span><span class="p">,</span> <span class="n">StaticGridPerChannelQuantizer</span><span class="p">,</span> <span class="n">ParamPerChannelQuantizer</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.quantsim_config.quantsim_config</span> <span class="kn">import</span> <span class="n">QuantSimConfigurator</span><span class="p">,</span> <span class="n">INPUT_QUANTIZERS</span><span class="p">,</span> \
    <span class="n">OUTPUT_QUANTIZERS</span><span class="p">,</span> <span class="n">PARAM_QUANTIZERS</span>
<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.utils.common</span> <span class="kn">import</span> <span class="n">convert_h5_model_to_pb_model</span>

<span class="kn">from</span> <span class="nn">aimet_tensorflow.keras.defs</span> <span class="kn">import</span> <span class="n">AxisHandling</span>
<span class="kn">import</span> <span class="nn">aimet_tensorflow.keras.utils.common</span> <span class="k">as</span> <span class="nn">keras_common_utils</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">AimetLogger</span><span class="o">.</span><span class="n">get_area_logger</span><span class="p">(</span><span class="n">AimetLogger</span><span class="o">.</span><span class="n">LogAreas</span><span class="o">.</span><span class="n">Quant</span><span class="p">)</span>

<span class="n">unquantizable_modules</span> <span class="o">=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">,</span> <span class="n">QcQuantizeWrapper</span><span class="p">)</span>
<span class="n">substitutable_modules</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MultiHeadAttention</span><span class="p">:</span> <span class="n">QcQuantizableMultiHeadAttention</span>
<span class="p">}</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">QuantizationSimModelParams</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data class that holds parameters for QuantizationSimModel. Used specifically to rebuild after converting to TF frozen pb</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">quant_scheme</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">QuantScheme</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;tf_enhanced&#39;</span>
    <span class="n">rounding_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nearest&#39;</span>
    <span class="n">default_output_bw</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">default_param_bw</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">in_place</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">config_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">default_data_type</span><span class="p">:</span> <span class="n">QuantizationDataType</span> <span class="o">=</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span>

<span class="c1"># pylint: disable=too-many-ancestors</span>
<span class="c1"># pylint: disable=too-many-instance-attributes</span>
<div class="viewcode-block" id="QuantizationSimModel"><a class="viewcode-back" href="../../../api_docs/keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel">[docs]</a><span class="k">class</span> <span class="nc">QuantizationSimModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements mechanism to add quantization simulations ops to a model. This allows for off-target simulation of</span>
<span class="sd">    inference accuracy. Also allows the model to be fine-tuned to counter the effects of quantization.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="c1"># pylint: disable=unused-argument</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">QuantScheme</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;tf_enhanced&#39;</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;nearest&#39;</span><span class="p">,</span>
                 <span class="n">default_output_bw</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">in_place</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">config_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">:</span> <span class="n">QuantizationDataType</span> <span class="o">=</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param model: Model to quantize</span>
<span class="sd">        :param quant_scheme: Quantization Scheme, currently supported schemes are post_training_tf and</span>
<span class="sd">               post_training_tf_enhanced, defaults to post_training_tf_enhanced</span>
<span class="sd">        :param rounding_mode: The round scheme to used. One of: &#39;nearest&#39; or &#39;stochastic&#39;, defaults to &#39;nearest&#39;.</span>
<span class="sd">        :param default_output_bw: bitwidth to use for activation tensors, defaults to 8</span>
<span class="sd">        :param default_param_bw: bitwidth to use for parameter tensors, defaults to 8</span>
<span class="sd">        :param in_place: If True, then the given &#39;model&#39; is modified in-place to add quant-sim nodes.</span>
<span class="sd">                Only suggested use of this option is when the user wants to avoid creating a copy of the model</span>
<span class="sd">        :param config_file: Path to a config file to use to specify rules for placing quant ops in the model</span>
<span class="sd">        :param default_data_type: Default data type to use for quantizing all layer parameters.</span>
<span class="sd">                                 Possible options are QuantizationDataType.int and QuantizationDataType.float.</span>
<span class="sd">                                 Note that the mode default_data_type=QuantizationDataType.float is only supported with</span>
<span class="sd">                                 default_output_bw=16 and default_param_bw=16</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QuantizationSimModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">in_place</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">n_weights</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[:</span><span class="n">n_weights</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_layer_name_to_quant_wrapper</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_substituted_layer</span> <span class="o">=</span> <span class="p">{}</span>    <span class="c1"># to hold the substituted layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_model</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connected_graph</span> <span class="o">=</span> <span class="n">ConnectedGraph</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_quantsim_configurator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_quantsim_configurator</span><span class="p">(</span><span class="n">quant_scheme</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span>
                                                                             <span class="n">default_output_bw</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">,</span>
                                                                             <span class="n">default_data_type</span><span class="p">,</span> <span class="n">config_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quant_scheme</span> <span class="o">=</span> <span class="n">quant_scheme</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_percentile_value</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># default percentile value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_channel_quantization_enabled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantsim_configurator</span><span class="o">.</span><span class="n">per_channel_quantization_flag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_quantization_wrappers</span><span class="p">(</span><span class="n">quant_scheme</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span>
                                                     <span class="n">default_output_bw</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quant_args</span> <span class="o">=</span> <span class="n">extract_global_quantizer_args</span><span class="p">(</span><span class="n">quant_scheme</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantsim_configurator</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_params</span> <span class="o">=</span> <span class="n">QuantizationSimModelParams</span><span class="p">(</span><span class="n">quant_scheme</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span> <span class="n">default_output_bw</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">,</span>
                                                  <span class="n">in_place</span><span class="p">,</span> <span class="n">config_file</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check that model is appropriate for quantsim.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">multiple_inbound_node_layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">multiple_inbound_node_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">multiple_inbound_node_layers</span><span class="p">:</span>
            <span class="n">error_msg</span> <span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Layers with more than one inbound nodes are unsupported. This may occur if a layer is &#39;</span>
                         <span class="sa">f</span><span class="s1">&#39;reused multiple times in the model definition.</span><span class="se">\n</span><span class="s1">&#39;</span>
                         <span class="sa">f</span><span class="s1">&#39;Layers with multiple inbound nodes: </span><span class="si">{</span><span class="n">multiple_inbound_node_layers</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_quantizer_list</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Method to provide a list of input, output and parameter quantizers</span>
<span class="sd">        :return: Three lists containing input, paramater and output quantizers respectively</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_quantizers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">parameter_quantizers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_quantizers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">quantizer</span> <span class="ow">in</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">:</span>
                <span class="n">input_quantizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantizer</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">quantizer</span> <span class="ow">in</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">:</span>
                <span class="n">parameter_quantizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantizer</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">quantizer</span> <span class="ow">in</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">:</span>
                <span class="n">output_quantizers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantizer</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_quantizers</span><span class="p">,</span> <span class="n">parameter_quantizers</span><span class="p">,</span> <span class="n">output_quantizers</span>

    <span class="k">def</span> <span class="nf">set_percentile_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">percentile_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the percentile value to be used while computing encodings for quantizers having percentile quant scheme.</span>

<span class="sd">        :param percentile_value: Percentile value to be set to</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">percentile_value</span> <span class="o">&lt;</span> <span class="mi">90</span> <span class="ow">or</span> <span class="n">percentile_value</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Percentile value must be in range [90, 100]&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_percentile_value</span> <span class="o">=</span> <span class="n">percentile_value</span>

        <span class="c1"># Set the percentile value to the activation quantizers</span>
        <span class="n">input_quantizers</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">output_quantizers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantizer_list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">quantizer</span> <span class="ow">in</span> <span class="n">input_quantizers</span> <span class="o">+</span> <span class="n">output_quantizers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">quant_scheme</span> <span class="o">==</span> <span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_percentile</span><span class="p">:</span>
                <span class="n">quantizer</span><span class="o">.</span><span class="n">set_percentile_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_percentile_value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_quantsim_configurator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">QuantScheme</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">rounding_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                                          <span class="n">default_output_bw</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                                          <span class="n">default_data_type</span><span class="p">:</span> <span class="n">QuantizationDataType</span> <span class="o">=</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">,</span>
                                          <span class="n">config_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QuantSimConfigurator</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize quantsim configurator</span>
<span class="sd">        :param quant_scheme: Quantization Scheme</span>
<span class="sd">        :param rounding_mode: The round scheme to used</span>
<span class="sd">        :param default_output_bw: bitwidth to use for activation tensors</span>
<span class="sd">        :param default_param_bw: bitwidth to use for parameter tensors</span>
<span class="sd">        :param default_data_type: data type to use for the parameter tensors</span>
<span class="sd">        :param config_file: Path to a config file to use to specify rules for placing quant ops in the model</span>
<span class="sd">        :return: QuantSimConfigurator</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">QuantSimConfigurator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">connected_graph</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span>
                                    <span class="n">default_output_bw</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">,</span> <span class="n">config_file</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_add_quantization_wrappers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span>
                                   <span class="n">default_output_bw</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add quantization wrappers to the model and return a new model with the wrappers inserted.</span>
<span class="sd">        :param quant_scheme: Quantization scheme to use</span>
<span class="sd">        :param rounding_mode: Rounding mode to use</span>
<span class="sd">        :param default_output_bw: Default bitwidth for activation quantizers</span>
<span class="sd">        :param default_param_bw: Default bitwidth for param quantizers</span>
<span class="sd">        :param default_data_type: data type to use for param quantizers</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">wrap_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">:</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Function to wrap layers with QcQuantizeWrappers, used by keras clone_model()</span>
<span class="sd">            :param layer: Layer to wrap</span>
<span class="sd">            :return: Wrapped layer, or original layer if layer is not to be wrapped</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">activation_quant_settings</span> <span class="o">=</span> <span class="n">QuantizerSettings</span><span class="p">(</span><span class="n">default_output_bw</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span>
                                                          <span class="n">quant_scheme</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="n">param_quant_settings</span> <span class="o">=</span> <span class="n">QuantizerSettings</span><span class="p">(</span><span class="n">default_param_bw</span><span class="p">,</span> <span class="n">default_data_type</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="p">,</span>
                                                     <span class="n">quant_scheme</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">substitutable_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                <span class="n">new_class</span> <span class="o">=</span> <span class="n">substitutable_modules</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)]</span>
                <span class="n">config</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
                <span class="n">config</span><span class="p">[</span><span class="s2">&quot;copy_source_weights&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
                <span class="n">wrapped_layer</span> <span class="o">=</span> <span class="n">new_class</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_substituted_layer</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="o">=</span> <span class="n">wrapped_layer</span>
                <span class="k">return</span> <span class="n">wrapped_layer</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">clone_function</span><span class="o">=</span><span class="n">wrap_layer</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">unquantizable_modules</span><span class="p">)</span> <span class="ow">or</span> <span class="n">layer</span><span class="o">.</span><span class="n">submodules</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">layer</span>

            <span class="n">input_quantizers</span><span class="p">,</span> <span class="n">output_quantizers</span><span class="p">,</span> <span class="n">param_quantizers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantizers_by_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="n">wrapper</span> <span class="o">=</span> <span class="n">QcQuantizeWrapper</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">activation_quant_settings</span><span class="p">,</span> <span class="n">param_quant_settings</span><span class="p">,</span>
                                        <span class="n">num_inputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keras_inputs</span><span class="p">),</span>
                                        <span class="n">input_quantizers</span><span class="o">=</span><span class="n">input_quantizers</span><span class="p">,</span>
                                        <span class="n">output_quantizers</span><span class="o">=</span><span class="n">output_quantizers</span><span class="p">,</span>
                                        <span class="n">param_quantizers</span><span class="o">=</span><span class="n">param_quantizers</span><span class="p">,</span>
                                        <span class="n">per_channel_quantization_enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">per_channel_quantization_enabled</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_layer_name_to_quant_wrapper</span><span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">wrapper</span>
            <span class="k">return</span> <span class="n">wrapper</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="p">,</span> <span class="n">clone_function</span><span class="o">=</span><span class="n">wrap_layer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_quantizers_by_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">ActivationTensorQuantizer</span><span class="p">],</span>
                                                                              <span class="n">Optional</span><span class="p">[</span><span class="n">ActivationTensorQuantizer</span><span class="p">],</span>
                                                                              <span class="n">Union</span><span class="p">[</span><span class="n">ParamPerTensorQuantizer</span><span class="p">,</span>
                                                                                    <span class="n">ParamPerChannelQuantizer</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get input/output/param quantizers from quantizers dictionary or initialize quantizers if layer is not found</span>
<span class="sd">        :param layer: Target layer</span>
<span class="sd">        :return: tuple of input, output, param quantizers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">quantizers_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantsim_configurator</span><span class="o">.</span><span class="n">get_quantizers_dict</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">quantizers_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> not found in quantizers dict, will generate quantizers automatically&quot;</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="n">input_quantizers</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">output_quantizers</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">param_quantizers</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_quantizers</span> <span class="o">=</span> <span class="n">quantizers_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">INPUT_QUANTIZERS</span><span class="p">)</span>
            <span class="n">output_quantizers</span> <span class="o">=</span> <span class="n">quantizers_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">OUTPUT_QUANTIZERS</span><span class="p">)</span>
            <span class="n">param_quantizers</span> <span class="o">=</span> <span class="n">quantizers_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">PARAM_QUANTIZERS</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_quantizers</span><span class="p">,</span> <span class="n">output_quantizers</span><span class="p">,</span> <span class="n">param_quantizers</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_quantizer_to_name_tuple</span><span class="p">(</span><span class="n">quantizers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorQuantizer</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Converts a list of quantizers to a tuple of quantizer names</span>
<span class="sd">        :param quantizers: quantizers</span>
<span class="sd">        :return: tuple of quantizer names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">quant_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">quantizers</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">quantizer</span> <span class="ow">in</span> <span class="n">quantizers</span><span class="p">:</span>
            <span class="n">quant_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantizer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">quant_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_quantizer_name_by_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
                                                                                 <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
                                                                                 <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the names of input, output and param quantizers</span>
<span class="sd">        :param layer: the keras layer</span>
<span class="sd">        :return: Tuple of quantizer names</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_quantizers</span><span class="p">,</span> <span class="n">output_quantizers</span><span class="p">,</span> <span class="n">param_quantizers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantizers_by_layer</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="n">output_quantizers_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantizer_to_name_tuple</span><span class="p">(</span><span class="n">output_quantizers</span><span class="p">)</span>
        <span class="n">input_quantizers_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantizer_to_name_tuple</span><span class="p">(</span><span class="n">input_quantizers</span><span class="p">)</span>
        <span class="n">parameter_quantizers_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantizer_to_name_tuple</span><span class="p">(</span><span class="n">param_quantizers</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_quantizers_names</span><span class="p">,</span> <span class="n">output_quantizers_names</span><span class="p">,</span> <span class="n">parameter_quantizers_names</span>

    <span class="k">def</span> <span class="nf">_disable_quantizers_in_folded_batchnorm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Disable input/output/param quantizers if layer is folded batch normalization</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">quantsim_wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer_name_to_quant_wrapper</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">GraphSearchUtils</span><span class="o">.</span><span class="n">is_folded_batch_normalization</span><span class="p">(</span><span class="n">quantsim_wrapper</span><span class="o">.</span><span class="n">original_layer</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">quantsim_wrapper</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">:</span>
                    <span class="n">q</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">quantsim_wrapper</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">:</span>
                    <span class="n">q</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">q</span> <span class="ow">in</span> <span class="n">quantsim_wrapper</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">:</span>
                    <span class="n">q</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_get_encoding_dict_for_quantizer</span><span class="p">(</span><span class="n">quantizer</span><span class="p">:</span> <span class="n">TensorQuantizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
                                                                              <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get encoding dict for a tensor quantizer.</span>
<span class="sd">        :param quantizer: Quantizer to get encoding info from</span>
<span class="sd">        :return: Dictionary or List of dictionaries containing encodings info for the tensor quantizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">quantizer_encodings</span> <span class="o">=</span> <span class="p">[</span><span class="n">quantizer</span><span class="o">.</span><span class="n">encoding</span><span class="p">]</span> <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">quantizer</span><span class="p">,</span> <span class="n">ParamPerChannelQuantizer</span><span class="p">)</span>
                                                       <span class="ow">or</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">float</span><span class="p">)</span> <span class="k">else</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">encoding</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="o">.</span><span class="n">min</span><span class="p">,</span>
                <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="o">.</span><span class="n">max</span><span class="p">,</span>
                <span class="s1">&#39;scale&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="o">.</span><span class="n">delta</span><span class="p">,</span>
                <span class="s1">&#39;offset&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">offset</span><span class="p">),</span>
                <span class="s1">&#39;bitwidth&#39;</span><span class="p">:</span> <span class="n">encoding</span><span class="o">.</span><span class="n">bw</span><span class="p">,</span>
                <span class="s1">&#39;is_symmetric&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">quantizer</span><span class="o">.</span><span class="n">is_symmetric</span><span class="p">),</span>
                <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="s1">&#39;int&#39;</span>
            <span class="p">}</span> <span class="k">if</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span>
            <span class="k">else</span> <span class="p">{</span><span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="s1">&#39;float&#39;</span><span class="p">,</span> <span class="s1">&#39;bitwidth&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">quantizer</span><span class="o">.</span><span class="n">bitwidth</span><span class="p">)}</span>
            <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">quantizer_encodings</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_encodings_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get encodings dict containing all activation and parameter encodings info in the model</span>
<span class="sd">        :return: Dictionary containing all activation and parameter encodings info in the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">activation_encodings</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">param_encodings</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">input_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">input_quantizer</span><span class="o">.</span><span class="n">is_encoding_valid</span><span class="p">()</span> <span class="ow">or</span> <span class="n">input_quantizer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">float</span><span class="p">:</span>
                    <span class="c1"># because dense layers in quantizable MHA are not explicitly sublayers, they don&#39;t have their</span>
                    <span class="c1"># inbound_nodes parameter populated, so the name of the quantizer is used instead</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
                        <span class="n">tensor_name</span> <span class="o">=</span> <span class="s2">&quot;multi_head_attention/&quot;</span> <span class="o">+</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">input_quantizer</span><span class="o">.</span><span class="n">name</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tensor_name</span> <span class="o">=</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keras_inputs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
                    <span class="n">encoding_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_encoding_dict_for_quantizer</span><span class="p">(</span><span class="n">input_quantizer</span><span class="p">)</span>
                    <span class="n">activation_encodings</span><span class="p">[</span><span class="n">tensor_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoding_dict</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">param_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">is_encoding_valid</span><span class="p">()</span> <span class="ow">or</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">float</span><span class="p">:</span>
                    <span class="n">param_name</span> <span class="o">=</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
                    <span class="n">encoding_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_encoding_dict_for_quantizer</span><span class="p">(</span><span class="n">param_quantizer</span><span class="p">)</span>
                    <span class="n">param_encodings</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoding_dict</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">output_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">output_quantizer</span><span class="o">.</span><span class="n">is_encoding_valid</span><span class="p">()</span> <span class="ow">or</span> <span class="n">output_quantizer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">float</span><span class="p">:</span>
                    <span class="c1"># because dense layers in quantizable MHA are not explicitly sublayers, they don&#39;t have their</span>
                    <span class="c1"># inbound_nodes parameter populated, so the name of the quantizer is used instead</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
                        <span class="n">tensor_name</span> <span class="o">=</span> <span class="s2">&quot;multi_head_attention/&quot;</span> <span class="o">+</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">output_quantizer</span><span class="o">.</span><span class="n">name</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tensor_name</span> <span class="o">=</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">name</span>
                    <span class="n">encoding_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_encoding_dict_for_quantizer</span><span class="p">(</span><span class="n">output_quantizer</span><span class="p">)</span>
                    <span class="n">activation_encodings</span><span class="p">[</span><span class="n">tensor_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoding_dict</span>
        <span class="n">encodings_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;version&#39;</span><span class="p">:</span> <span class="n">encoding_version</span><span class="p">,</span>
                          <span class="s1">&#39;activation_encodings&#39;</span><span class="p">:</span> <span class="n">activation_encodings</span><span class="p">,</span>
                          <span class="s1">&#39;param_encodings&#39;</span><span class="p">:</span> <span class="n">param_encodings</span><span class="p">,</span>
                          <span class="s1">&#39;quantizer_args&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_args</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;quant_args&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="p">{}}</span>
        <span class="k">return</span> <span class="n">encodings_dict</span>

<div class="viewcode-block" id="QuantizationSimModel.compute_encodings"><a class="viewcode-back" href="../../../api_docs/keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel.compute_encodings">[docs]</a>    <span class="k">def</span> <span class="nf">compute_encodings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">forward_pass_callback</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes encodings for all quantization sim nodes in the model.</span>
<span class="sd">        :param forward_pass_callback: A callback function that is expected to runs forward passes on a model.</span>
<span class="sd">               This callback function should use representative data for the forward pass, so the calculated</span>
<span class="sd">               encodings work for all data samples.</span>
<span class="sd">        :param forward_pass_callback_args: These argument(s) are passed to the forward_pass_callback as-is. Up to</span>
<span class="sd">               the user to determine the type of this parameter. E.g. could be simply an integer representing the number</span>
<span class="sd">               of data samples to use. Or could be a tuple of parameters or an object representing something more</span>
<span class="sd">               complex.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ops_with_invalid_encodings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compute_and_set_parameter_encodings</span><span class="p">(</span><span class="n">ops_with_invalid_encodings</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_op_mode_parameters</span><span class="p">(</span><span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="o">.</span><span class="n">quantizeDequantize</span><span class="p">)</span>

        <span class="n">forward_pass_callback</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">forward_pass_callback_args</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">quant_wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="n">quant_wrapper</span><span class="o">.</span><span class="n">compute_encoding</span><span class="p">(</span><span class="n">ops_with_invalid_encodings</span><span class="p">)</span>

        <span class="n">op_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_op_mode_after_analysis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quant_scheme</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_op_mode_parameters</span><span class="p">(</span><span class="n">op_mode</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ops_with_invalid_encodings</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;The following quantizers did not have valid encodings and have been set to passThrough mode: &#39;</span>
                         <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ops_with_invalid_encodings</span><span class="p">)</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;This can be due to the quantizers not having been evaluated during the forward pass in &#39;</span>
                         <span class="s1">&#39;compute encodings. Evaluation is required to collect statistics needed to compute valid &#39;</span>
                         <span class="s1">&#39;encodings.</span><span class="se">\n</span><span class="s1">&#39;</span>
                         <span class="s1">&#39;As a result, the quantizers have been set to passThrough mode, meaning no quantization noise &#39;</span>
                         <span class="s1">&#39;will be simulated for these ops if they are evaluated in the future.</span><span class="se">\n</span><span class="s1">&#39;</span>
                         <span class="s1">&#39;If this is not desired, amend the forward pass to evaluate tensors which require these ops &#39;</span>
                         <span class="s1">&#39;to be evaluated, and recompute encodings.&#39;</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_set_op_mode_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op_mode</span><span class="p">:</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets quant mode for parameters and if the encodings are invalid, then adds those wrappers</span>
<span class="sd">        to wrappers_with_invalid_encodings</span>
<span class="sd">        :param op_mode: Quant mode to set to</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">quantizer_info</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">param_quantizer</span> <span class="ow">in</span> <span class="n">quantizer_info</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                    <span class="n">param_quantizer</span><span class="o">.</span><span class="n">quant_mode</span> <span class="o">=</span> <span class="n">op_mode</span>

<div class="viewcode-block" id="QuantizationSimModel.export"><a class="viewcode-back" href="../../../api_docs/keras_quantsim.html#aimet_tensorflow.keras.quantsim.QuantizationSimModel.export">[docs]</a>    <span class="k">def</span> <span class="nf">export</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method exports out the quant-sim model so it is ready to be run on-target.</span>
<span class="sd">        Specifically, the following are saved</span>
<span class="sd">        1. The sim-model is exported to a regular Keras model without any simulation ops</span>
<span class="sd">        2. The quantization encodings are exported to a separate JSON-formatted file that can</span>
<span class="sd">           then be imported by the on-target runtime (if desired)</span>
<span class="sd">        :param path: path where to store model pth and encodings</span>
<span class="sd">        :param filename_prefix: Prefix to use for filenames of the model pth and encodings files</span>
<span class="sd">        :param custom_objects: If there are custom objects to load, Keras needs a dict of them to map them</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename_prefix</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_path</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span><span class="p">,</span> <span class="n">save_format</span><span class="o">=</span><span class="s1">&#39;h5&#39;</span><span class="p">)</span>

        <span class="c1"># Conversion of saved h5 model to pb model for consumption by SNPE/QNN</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">convert_h5_model_to_pb_model</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s1">.h5&#39;</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">custom_objects</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Could not convert h5 to frozen pb. &quot;</span>
                          <span class="s2">&quot;Please call export() again with custom_objects defined.&quot;</span><span class="p">)</span>
            <span class="k">raise</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">encodings_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_encodings_dict</span><span class="p">()</span>
            <span class="n">encoding_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">filename_prefix</span> <span class="o">+</span> <span class="s1">&#39;.encodings&#39;</span><span class="p">)</span>
            <span class="n">save_json_yaml</span><span class="p">(</span><span class="n">encoding_file_path</span><span class="p">,</span> <span class="n">encodings_dict</span><span class="p">)</span>

            <span class="c1"># Keras magic under the hood that causes the &#39;Invalid Graph&#39; error to go away</span>
            <span class="c1"># TODO: Investigate what is actually fixing this issue.</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_without_wrappers</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_compute_and_set_parameter_encodings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ops_with_invalid_encodings</span><span class="p">:</span> <span class="n">List</span><span class="p">):</span>
        <span class="c1"># pylint: disable=too-many-nested-blocks</span>
        <span class="k">for</span> <span class="n">quantizer_wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">param_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">quantizer_wrapper</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">()</span> <span class="ow">and</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">QuantizationDataType</span><span class="o">.</span><span class="n">int</span><span class="p">:</span>
                    <span class="c1"># 0th input to our quant wrapper is the tensor being quantized</span>
                    <span class="n">weight_tensor</span> <span class="o">=</span> <span class="n">quantizer_wrapper</span><span class="o">.</span><span class="n">original_layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="n">idx</span><span class="p">]</span>

                    <span class="c1"># Per-channel</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_quantizer</span><span class="p">,</span> <span class="n">StaticGridPerChannelQuantizer</span><span class="p">):</span>
                        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">tensor_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">param_quantizer</span><span class="o">.</span><span class="n">tensor_quantizer</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">axis_handling</span> <span class="o">==</span> <span class="n">AxisHandling</span><span class="o">.</span><span class="n">LAST_TWO_AXES</span><span class="o">.</span><span class="n">value</span><span class="p">:</span>
                                <span class="n">last_two_axes_combined_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weight_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                                <span class="n">channel_slice</span> <span class="o">=</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">last_two_axes_combined_shape</span><span class="p">)</span>
                                <span class="n">channel_slice</span> <span class="o">=</span> <span class="n">channel_slice</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">channel_slice</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">quantizer_wrapper</span><span class="o">.</span><span class="n">original_layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="p">):</span>
                                <span class="k">if</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                                    <span class="n">channel_slice</span> <span class="o">=</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
                                <span class="k">else</span><span class="p">:</span>
                                    <span class="c1"># For bias in Transpose layers</span>
                                    <span class="n">channel_slice</span> <span class="o">=</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">channel_slice</span> <span class="o">=</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="n">tensor_quantizer</span><span class="o">.</span><span class="n">updateStats</span><span class="p">(</span><span class="n">channel_slice</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

                    <span class="c1"># Per-tensor</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">tensor_quantizer</span> <span class="o">=</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">tensor_quantizer</span>
                        <span class="n">tensor_quantizer</span><span class="o">.</span><span class="n">updateStats</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

                    <span class="n">param_quantizer</span><span class="o">.</span><span class="n">compute_encoding</span><span class="p">(</span><span class="n">ops_with_invalid_encodings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_and_freeze_param_encodings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoding_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set and freeze parameter encodings from encodings JSON file</span>
<span class="sd">        :param encoding_path: path from where to load parameter encodings file</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Load parameter encodings file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">encoding_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
            <span class="n">param_encodings</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_file</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">quant_wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="n">quant_wrapper</span><span class="o">.</span><span class="n">set_and_freeze_param_encoding</span><span class="p">(</span><span class="n">param_encodings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_encodings_to_sim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoding_file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the saved encodings to quant sim model</span>

<span class="sd">        :param encoding_file_path: path from where to load encodings file</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=protected-access, too-many-branches, too-many-locals, too-many-statements</span>
        <span class="c1"># Load encodings file</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">encoding_file_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
            <span class="n">encodings</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">json_file</span><span class="p">)</span>

        <span class="n">param_encodings</span> <span class="o">=</span> <span class="n">encodings</span><span class="p">[</span><span class="s1">&#39;param_encodings&#39;</span><span class="p">]</span>
        <span class="n">activation_encodings</span> <span class="o">=</span> <span class="n">encodings</span><span class="p">[</span><span class="s1">&#39;activation_encodings&#39;</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">wrapper</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">input_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">input_quantizers</span><span class="p">):</span>
                <span class="c1"># because dense layers in quantizable MHA are not explicitly sublayers, they don&#39;t have their</span>
                <span class="c1"># inbound_nodes parameter populated, so the name of the quantizer is used instead</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
                    <span class="n">tensor_name</span> <span class="o">=</span> <span class="s2">&quot;multi_head_attention/&quot;</span> <span class="o">+</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">input_quantizer</span><span class="o">.</span><span class="n">name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tensor_name</span> <span class="o">=</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keras_inputs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>

                <span class="k">if</span> <span class="n">tensor_name</span> <span class="ow">in</span> <span class="n">activation_encodings</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">input_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Not loading encodings for quantizer: </span><span class="si">%s</span><span class="s2"> as it is disabled&quot;</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="n">encoding</span><span class="p">,</span> <span class="n">is_symmetric</span> <span class="o">=</span> <span class="n">keras_common_utils</span><span class="o">.</span><span class="n">create_encoding_from_dict</span><span class="p">(</span><span class="n">activation_encodings</span><span class="p">[</span><span class="n">tensor_name</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">input_quantizer</span><span class="o">.</span><span class="n">tensor_quantizer</span><span class="o">.</span><span class="n">isEncodingValid</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">input_quantizer</span><span class="o">.</span><span class="n">set_quantizer_encodings</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">bw</span><span class="p">,</span> <span class="n">is_symmetric</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span>
                                                            <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="o">.</span><span class="n">quantizeDequantize</span><span class="p">)</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting encodings for : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">input_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                        <span class="n">input_quantizer</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>
                        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Encoding for quantizer: </span><span class="si">%s</span><span class="s2"> is not present thus disabling it.&quot;</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">param_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">):</span>
                <span class="n">param_name</span> <span class="o">=</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>

                <span class="k">if</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">param_encodings</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Not loading encodings for parameter: </span><span class="si">%s</span><span class="s2"> as quantizer is disabled&quot;</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_quantizer</span><span class="p">,</span> <span class="n">StaticGridPerChannelQuantizer</span><span class="p">):</span>
                        <span class="n">encoding</span><span class="p">,</span> <span class="n">is_symmetric</span> <span class="o">=</span> <span class="n">keras_common_utils</span><span class="o">.</span><span class="n">create_encoding_from_dict</span><span class="p">(</span><span class="n">param_encodings</span><span class="p">[</span><span class="n">param_name</span><span class="p">])</span>
                        <span class="k">for</span> <span class="n">tensor_quantizer</span> <span class="ow">in</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">tensor_quantizer</span><span class="p">:</span>
                            <span class="n">tensor_quantizer</span><span class="o">.</span><span class="n">isEncodingValid</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">bw</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bw</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">encoding</span><span class="p">,</span> <span class="n">is_symmetric</span> <span class="o">=</span> <span class="n">keras_common_utils</span><span class="o">.</span><span class="n">create_encoding_from_dict</span><span class="p">(</span><span class="n">param_encodings</span><span class="p">[</span><span class="n">param_name</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                        <span class="n">param_quantizer</span><span class="o">.</span><span class="n">tensor_quantizer</span><span class="o">.</span><span class="n">isEncodingValid</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">bw</span> <span class="o">=</span> <span class="n">encoding</span><span class="o">.</span><span class="n">bw</span>
                    <span class="n">param_quantizer</span><span class="o">.</span><span class="n">set_quantizer_encodings</span><span class="p">(</span><span class="n">bw</span><span class="p">,</span> <span class="n">is_symmetric</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span>
                                                            <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="o">.</span><span class="n">oneShotQuantizeDequantize</span><span class="p">)</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting encodings for : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                        <span class="n">param_quantizer</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>
                        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Encoding for parameter: </span><span class="si">%s</span><span class="s2"> not present thus disabling this quantizer.&quot;</span><span class="p">,</span> <span class="n">param_name</span><span class="p">)</span>

            <span class="c1"># Loading encodings means that compute encodings was called. Therefore, these two lines set the correct</span>
            <span class="c1"># op mode for the correct quant scheme and if the quantization was per channel or not.</span>
            <span class="n">op_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_op_mode_after_analysis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quant_scheme</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_op_mode_parameters</span><span class="p">(</span><span class="n">op_mode</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">output_quantizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wrapper</span><span class="o">.</span><span class="n">output_quantizers</span><span class="p">):</span>
                <span class="c1"># because dense layers in quantizable MHA are not explicitly sublayers, they don&#39;t have their</span>
                <span class="c1"># inbound_nodes parameter populated, so the name of the quantizer is used instead</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
                    <span class="n">tensor_name</span> <span class="o">=</span> <span class="s2">&quot;multi_head_attention/&quot;</span> <span class="o">+</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">output_quantizer</span><span class="o">.</span><span class="n">name</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">tensor_name</span> <span class="o">=</span> <span class="n">wrapper</span><span class="o">.</span><span class="n">_layer_to_wrap</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">name</span>

                <span class="k">if</span> <span class="n">tensor_name</span> <span class="ow">in</span> <span class="n">activation_encodings</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">output_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Not loading encodings for quantizer: </span><span class="si">%s</span><span class="s2"> as it is disabled&quot;</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">)</span>
                        <span class="k">continue</span>
                    <span class="n">encoding</span><span class="p">,</span> <span class="n">is_symmetric</span> <span class="o">=</span> <span class="n">keras_common_utils</span><span class="o">.</span><span class="n">create_encoding_from_dict</span><span class="p">(</span><span class="n">activation_encodings</span><span class="p">[</span><span class="n">tensor_name</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">output_quantizer</span><span class="o">.</span><span class="n">tensor_quantizer</span><span class="o">.</span><span class="n">isEncodingValid</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">output_quantizer</span><span class="o">.</span><span class="n">set_quantizer_encodings</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">bw</span><span class="p">,</span> <span class="n">is_symmetric</span><span class="p">,</span> <span class="n">encoding</span><span class="p">,</span>
                                                             <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="o">.</span><span class="n">quantizeDequantize</span><span class="p">)</span>
                    <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting encodings for : </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">output_quantizer</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
                        <span class="n">output_quantizer</span><span class="o">.</span><span class="n">disable</span><span class="p">()</span>
                        <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Encoding for quantizer: </span><span class="si">%s</span><span class="s2"> is not present thus disabling it.&quot;</span><span class="p">,</span> <span class="n">tensor_name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_param_op_mode_after_analysis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns quant mode to use for parameters after encodings have been computed</span>
<span class="sd">        :param quant_scheme: Quantization scheme to use</span>
<span class="sd">        :return: Quant mode to use</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">quant_scheme</span> <span class="ow">in</span> <span class="p">[</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">training_range_learning_with_tf_init</span><span class="p">,</span>
                            <span class="n">QuantScheme</span><span class="o">.</span><span class="n">training_range_learning_with_tf_enhanced_init</span><span class="p">]</span> \
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_channel_quantization_enabled</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="o">.</span><span class="n">quantizeDequantize</span>
        <span class="k">return</span> <span class="n">libpymo</span><span class="o">.</span><span class="n">TensorQuantizerOpMode</span><span class="o">.</span><span class="n">oneShotQuantizeDequantize</span>

    <span class="k">def</span> <span class="nf">quant_wrappers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generator for yielding all quantization wrappers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QcQuantizeWrapper</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">layer</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QcQuantizableMultiHeadAttention</span><span class="p">):</span>
                <span class="k">yield from</span> <span class="n">layer</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">()</span>

            <span class="c1"># For Getting Quantizers from Sequantial Block</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
                <span class="k">yield from</span> <span class="n">quant_wrappers_for_sequential_block</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_quant_wrapper_for_layer_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">QcQuantizeWrapper</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return qc quant wrapper corresponding to a layer name</span>
<span class="sd">        :param layer_name: Layer name to get quantize wrapper for</span>
<span class="sd">        :return: Qc quant wrapper corresponding to a layer name</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_layer_name_to_quant_wrapper</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">layer_name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_fill_missing_encoding_min_max_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="nb">list</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the encoding min/max gradients and populates the gradients list</span>
<span class="sd">        :param gradients: gradients computed using GradientTape(gradients for encoding min/max will be `None`)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">_find_weight_in_layer</span><span class="p">(</span><span class="n">weight_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_layer</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>

            <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">model_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">weight_name</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">weight</span>

            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># Mapping used to get the gradients of weights(kernel, bias etc)</span>
        <span class="n">weight_name_to_gradient</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">],</span>
                                           <span class="n">gradients</span><span class="p">))</span>

        <span class="c1"># Mapping used to get index of encoding min/max gradients (which would be `None`) and fill them</span>
        <span class="n">weight_name_to_index</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">],</span>
                                        <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">))))</span>

        <span class="c1"># Only process layers where &#39;param_quantizers&#39; is defined (i.e. QcQuantizeWrapper layers)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_layer</span><span class="p">:</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">_layer</span><span class="p">,</span> <span class="s1">&#39;param_quantizers&#39;</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">param_quantizer</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">param_quantizers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">weight_name_to_gradient</span><span class="p">:</span>
                    <span class="c1"># Value of weight associated with this param quantizer</span>
                    <span class="n">weight_tensor</span> <span class="o">=</span> <span class="n">_find_weight_in_layer</span><span class="p">(</span><span class="n">param_quantizer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">original_layer</span><span class="p">)</span>

                    <span class="c1"># Gradients of the weights</span>
                    <span class="n">grad</span> <span class="o">=</span> <span class="n">weight_name_to_gradient</span><span class="p">[</span><span class="n">param_quantizer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

                    <span class="c1"># Using the weights and it&#39;s gradients, compute gradients for encoding min/max</span>
                    <span class="n">dloss_by_dmin</span><span class="p">,</span> <span class="n">dloss_by_dmax</span> <span class="o">=</span> <span class="n">param_quantizer</span><span class="o">.</span><span class="n">get_gradients_for_encoding_min_max</span><span class="p">(</span><span class="n">weight_tensor</span><span class="p">,</span>
                                                                                                      <span class="n">grad</span><span class="p">)</span>

                    <span class="n">enc_min_index</span> <span class="o">=</span> <span class="n">weight_name_to_index</span><span class="p">[</span><span class="n">param_quantizer</span><span class="o">.</span><span class="n">encoding_min</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
                    <span class="n">enc_max_index</span> <span class="o">=</span> <span class="n">weight_name_to_index</span><span class="p">[</span><span class="n">param_quantizer</span><span class="o">.</span><span class="n">encoding_max</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

                    <span class="n">gradients</span><span class="p">[</span><span class="n">enc_min_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">dloss_by_dmin</span>
                    <span class="n">gradients</span><span class="p">[</span><span class="n">enc_max_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">dloss_by_dmax</span>

    <span class="c1"># pylint: disable=useless-super-delegation</span>
    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Custom training loop, equivalent to overriding `keras.Model.fit` function</span>
<span class="sd">        Reference: https://keras.io/guides/customizing_what_happens_in_fit/</span>
<span class="sd">        Only relevant when using range-learning, otherwise equivalent to `keras.Model.fit`</span>
<span class="sd">        Param quantizers are disconnected in the op graph of the wrapped model</span>
<span class="sd">        Because of this, the gradients are not computed for encoding min/max(when range learning is enabled)</span>
<span class="sd">        This custom train_step function computes the missing gradients for encoding min/max of param quantizers</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span>

        <span class="c1"># Manually compute missing gradients for encoding min/max when using range learning</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant_scheme</span> <span class="ow">in</span> <span class="p">[</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">training_range_learning_with_tf_init</span><span class="p">,</span>
                                 <span class="n">QuantScheme</span><span class="o">.</span><span class="n">training_range_learning_with_tf_enhanced_init</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fill_missing_encoding_min_max_gradients</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>

        <span class="n">gradients_to_apply</span> <span class="o">=</span> <span class="p">[(</span><span class="n">gradient</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="k">for</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span>
                              <span class="k">if</span> <span class="n">gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">gradients_to_apply</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_metrics</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span></div>


<span class="k">def</span> <span class="nf">quant_wrappers_for_sequential_block</span><span class="p">(</span><span class="n">seq_block</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generator for yielding all quantization wrappers for a Sequantial Block</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">seq_block</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QcQuantizeWrapper</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">layer</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QcQuantizableMultiHeadAttention</span><span class="p">):</span>
            <span class="k">yield from</span> <span class="n">layer</span><span class="o">.</span><span class="n">quant_wrappers</span><span class="p">()</span>

        <span class="c1"># in cases of nested Sequential Block</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
            <span class="k">yield from</span> <span class="n">quant_wrappers_for_sequential_block</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Qualcomm Innovation Center, Inc..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>