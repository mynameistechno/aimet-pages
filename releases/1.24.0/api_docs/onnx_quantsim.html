

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET ONNX Quantization SIM API &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../user_guide/index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../user_guide/index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET ONNX Quantization SIM API</a><ul>
<li><a class="reference internal" href="#top-level-api">Top-level API</a></li>
<li><a class="reference internal" href="#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-onnx-quantization-sim-api">
<span id="api-onnx-quantsim"></span><h1>AIMET ONNX Quantization SIM API<a class="headerlink" href="#aimet-onnx-quantization-sim-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="top-level-api">
<h2>Top-level API<a class="headerlink" href="#top-level-api" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="aimet_onnx.quantsim.QuantizationSimModel">
<em class="property">class </em><code class="sig-prename descclassname">aimet_onnx.quantsim.</code><code class="sig-name descname">QuantizationSimModel</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">quant_scheme=&lt;QuantScheme.post_training_tf_enhanced: 2&gt;</em>, <em class="sig-param">rounding_mode='nearest'</em>, <em class="sig-param">default_param_bw=8</em>, <em class="sig-param">default_activation_bw=8</em>, <em class="sig-param">use_symmetric_encodings=False</em>, <em class="sig-param">use_cuda=False</em>, <em class="sig-param">config_file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_onnx.quantsim.QuantizationSimModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a QuantizationSimModel model by adding quantization simulations ops to a given model</p>
<p>Constructor</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">ModelProto</span></code>) – ONNX model or path to model</p></li>
<li><p><strong>quant_scheme</strong> (<a class="reference internal" href="torch_quantsim.html#aimet_common.defs.QuantScheme" title="aimet_common.defs.QuantScheme"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantScheme</span></code></a>) – Quantization scheme (e.g. QuantScheme.post_training_tf)</p></li>
<li><p><strong>rounding_mode</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – Rounding mode (e.g. nearest)</p></li>
<li><p><strong>default_param_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Quantization bitwidth for parameter</p></li>
<li><p><strong>default_activation_bw</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Quantization bitwidth for activation</p></li>
<li><p><strong>use_symmetric_encodings</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True if symmetric encoding is used.  False otherwise.</p></li>
<li><p><strong>use_cuda</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – True if using CUDA to run quantization op. False otherwise.</p></li>
<li><p><strong>config_file</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>]) – Path to Configuration file for model quantizers</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>Note about Quantization Schemes</strong> : Since ONNX Runtime will be used for optimized inference only, ONNX
framework will support Post Training Quantization schemes i.e. TF or TF-enhanced to compute the encodings.</p>
<p><strong>The following API can be used to Compute Encodings for Model</strong></p>
<dl class="method">
<dt id="aimet_onnx.quantsim.QuantizationSimModel.compute_encodings">
<code class="sig-prename descclassname">QuantizationSimModel.</code><code class="sig-name descname">compute_encodings</code><span class="sig-paren">(</span><em class="sig-param">forward_pass_callback</em>, <em class="sig-param">forward_pass_callback_args</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_onnx.quantsim.QuantizationSimModel.compute_encodings" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute and return the encodings of each tensor quantizer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>forward_pass_callback</strong> – A callback function that simply runs forward passes on the model. This callback
function should use representative data for the forward pass, so the calculated encodings work for all
data samples. This callback internally chooses the number of data samples it wants to use for calculating
encodings.</p></li>
<li><p><strong>forward_pass_callback_args</strong> – These argument(s) are passed to the forward_pass_callback as-is. Up to
the user to determine the type of this parameter. E.g. could be simply an integer representing the number
of data samples to use. Or could be a tuple of parameters or an object representing something more complex.
If set to None, forward_pass_callback will be invoked with no parameters.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
<p><strong>The following API can be used to Export the Model to target</strong></p>
<dl class="method">
<dt id="aimet_onnx.quantsim.QuantizationSimModel.export">
<code class="sig-prename descclassname">QuantizationSimModel.</code><code class="sig-name descname">export</code><span class="sig-paren">(</span><em class="sig-param">path</em>, <em class="sig-param">filename_prefix</em><span class="sig-paren">)</span><a class="headerlink" href="#aimet_onnx.quantsim.QuantizationSimModel.export" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute encodings and export to files
:type path: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>
:param path: dir to save encoding files
:type filename_prefix: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>
:param filename_prefix: filename to save encoding files</p>
</dd></dl>

<div class="line-block">
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aimet_onnx.quantsim</span> <span class="kn">import</span> <span class="n">QuantizationSimModel</span>
<span class="kn">from</span> <span class="nn">aimet_common.defs</span> <span class="kn">import</span> <span class="n">QuantScheme</span>
</pre></div>
</div>
<p><strong>User should write this function to pass calibration data</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pass_calibration_data</span><span class="p">(</span><span class="n">session</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The User of the QuantizationSimModel API is expected to write this function based on their data set.</span>
<span class="sd">    This is not a working function and is provided only as a guideline.</span>

<span class="sd">    :param session: Model&#39;s session</span>
<span class="sd">    :return:</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># User action required</span>
    <span class="c1"># The following line of code is an example of how to use the ImageNet data&#39;s validation data loader.</span>
    <span class="c1"># Replace the following line with your own dataset&#39;s validation data loader.</span>
    <span class="n">data_loader</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Your Dataset&#39;s data loader</span>

    <span class="c1"># User action required</span>
    <span class="c1"># For computing the activation encodings, around 1000 unlabelled data samples are required.</span>
    <span class="c1"># Edit the following 2 lines based on your dataloader&#39;s batch size.</span>
    <span class="c1"># batch_size * max_batch_counter should be 1024</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">max_batch_counter</span> <span class="o">=</span> <span class="mi">16</span>

    <span class="n">input_tensor</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># input tensor in session</span>

    <span class="n">current_batch_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>

        <span class="n">current_batch_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">current_batch_counter</span> <span class="o">==</span> <span class="n">max_batch_counter</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
<p><strong>Quantize the model and finetune (QAT)</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quantize_model</span><span class="p">():</span>
    <span class="n">onnx_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">QuantizationSimModel</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span> <span class="n">quant_scheme</span><span class="o">=</span><span class="n">QuantScheme</span><span class="o">.</span><span class="n">post_training_tf</span><span class="p">,</span>
                               <span class="n">rounding_mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">default_param_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">default_activation_bw</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                               <span class="n">use_symmetric_encodings</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">sim</span><span class="o">.</span><span class="n">compute_encodings</span><span class="p">(</span><span class="n">pass_calibration_data</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Evaluate the quant sim</span>
    <span class="n">forward_pass_function</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">session</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>