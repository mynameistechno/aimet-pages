

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET PyTorch AutoQuant API &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../user_guide/index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../user_guide/index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET PyTorch AutoQuant API</a><ul>
<li><a class="reference internal" href="#user-guide-link">User Guide Link</a></li>
<li><a class="reference internal" href="#examples-notebook-link">Examples Notebook Link</a></li>
<li><a class="reference internal" href="#top-level-api">Top-level API</a></li>
<li><a class="reference internal" href="#code-examples">Code Examples</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-pytorch-autoquant-api">
<span id="api-torch-auto-quant"></span><h1>AIMET PyTorch AutoQuant API<a class="headerlink" href="#aimet-pytorch-autoquant-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="user-guide-link">
<h2>User Guide Link<a class="headerlink" href="#user-guide-link" title="Permalink to this headline">¶</a></h2>
<p>To learn more about this technique, please see <a class="reference internal" href="../user_guide/auto_quant.html#ug-auto-quant"><span class="std std-ref">AutoQuant</span></a></p>
</div>
<div class="section" id="examples-notebook-link">
<h2>Examples Notebook Link<a class="headerlink" href="#examples-notebook-link" title="Permalink to this headline">¶</a></h2>
<p>For an end-to-end notebook showing how to use PyTorch AutoQuant, please see <a class="reference internal" href="../Examples/torch/quantization/autoquant.html"><span class="doc">here</span></a>.</p>
</div>
<div class="section" id="top-level-api">
<h2>Top-level API<a class="headerlink" href="#top-level-api" title="Permalink to this headline">¶</a></h2>
<dl class="attribute">
<dt id="aimet_torch.auto_quant.AutoQuant">
<code class="sig-prename descclassname">aimet_torch.auto_quant.</code><code class="sig-name descname">AutoQuant</code><a class="headerlink" href="#aimet_torch.auto_quant.AutoQuant" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">aimet_torch.auto_quant._AutoQuantV1</span></code></p>
</dd></dl>

</div>
<div class="section" id="code-examples">
<h2>Code Examples<a class="headerlink" href="#code-examples" title="Permalink to this headline">¶</a></h2>
<p><strong>Required imports</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">SubsetRandomSampler</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="kn">from</span> <span class="nn">aimet_torch.adaround.adaround_weight</span> <span class="kn">import</span> <span class="n">AdaroundParameters</span>
<span class="kn">from</span> <span class="nn">aimet_torch.auto_quant</span> <span class="kn">import</span> <span class="n">AutoQuant</span>
</pre></div>
</div>
<p><strong>Define constants and helper functions</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">EVAL_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">CALIBRATION_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">_subset_samplers</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">def</span> <span class="nf">_create_sampled_data_loader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">num_samples</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_subset_samplers</span><span class="p">:</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)),</span> <span class="n">num_samples</span><span class="p">)</span>
        <span class="n">_subset_samplers</span><span class="p">[</span><span class="n">num_samples</span><span class="p">]</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                      <span class="n">sampler</span><span class="o">=</span><span class="n">_subset_samplers</span><span class="p">[</span><span class="n">num_samples</span><span class="p">],</span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Prepare model and dataset</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fp32_model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">((</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">))</span>
<span class="c1"># NOTE: In the actual use cases, a real dataset should provide by the users.</span>
<span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FakeData</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">EVAL_DATASET_SIZE</span><span class="p">,</span>
                                 <span class="n">image_size</span><span class="o">=</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>
                                 <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                 <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Prepare unlabeled dataset</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">class</span> <span class="nc">UnlabeledDatasetWrapper</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="n">dataset</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">images</span>

<span class="n">unlabeled_dataset</span> <span class="o">=</span> <span class="n">UnlabeledDatasetWrapper</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>
<span class="n">unlabeled_data_loader</span> <span class="o">=</span> <span class="n">_create_sampled_data_loader</span><span class="p">(</span><span class="n">unlabeled_dataset</span><span class="p">,</span> <span class="n">CALIBRATION_DATASET_SIZE</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Prepare eval callback</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NOTE: In the actual use cases, the users should implement this part to serve</span>
<span class="c1">#       their own goals if necessary.</span>
<span class="k">def</span> <span class="nf">eval_callback</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">)</span>

    <span class="n">eval_data_loader</span> <span class="o">=</span> <span class="n">_create_sampled_data_loader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>

    <span class="n">num_correct_predictions</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">eval_data_loader</span><span class="p">:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">num_correct_predictions</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_correct_predictions</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_samples</span>
</pre></div>
</div>
<p><strong>Create AutoQuant object</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">auto_quant</span> <span class="o">=</span> <span class="n">AutoQuant</span><span class="p">(</span><span class="n">allowed_accuracy_drop</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                       <span class="n">unlabeled_dataset_iterable</span><span class="o">=</span><span class="n">unlabeled_data_loader</span><span class="p">,</span>
                       <span class="n">eval_callback</span><span class="o">=</span><span class="n">eval_callback</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>(Optional) Set Adaround parameters</strong></p>
<p>For setting the num_batches parameter, use the following guideline.
The number of batches is used to evaluate the model while calculating the quantization encodings.
Typically we want AdaRound to use around 2000 samples.
For example, if the batch size is 32, num_batches is 64.
If the batch size you are using is different, adjust the num_batches accordingly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ADAROUND_DATASET_SIZE</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">adaround_data_loader</span> <span class="o">=</span> <span class="n">_create_sampled_data_loader</span><span class="p">(</span><span class="n">unlabeled_dataset</span><span class="p">,</span> <span class="n">ADAROUND_DATASET_SIZE</span><span class="p">)</span>
<span class="n">adaround_params</span> <span class="o">=</span> <span class="n">AdaroundParameters</span><span class="p">(</span><span class="n">adaround_data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">adaround_data_loader</span><span class="p">))</span>
<span class="n">auto_quant</span><span class="o">.</span><span class="n">set_adaround_params</span><span class="p">(</span><span class="n">adaround_params</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Run AutoQuant</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">encoding_path</span> <span class="o">=</span>\
    <span class="n">auto_quant</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">fp32_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span>
                     <span class="n">dummy_input_on_cpu</span><span class="o">=</span><span class="n">dummy_input</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
                     <span class="n">dummy_input_on_gpu</span><span class="o">=</span><span class="n">dummy_input</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>