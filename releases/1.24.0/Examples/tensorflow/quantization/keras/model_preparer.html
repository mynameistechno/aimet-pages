

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Keras Model Preparer &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</title>
    <link rel="stylesheet" href="../../../../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script type="text/javascript" src="../../../../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../../../user_guide/index.html">
              <img class="logo" src="../../../../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="../../../../user_guide/index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Keras Model Preparer</a><ul>
<li><a class="reference internal" href="#Overall-flow">Overall flow</a><ul>
<li><a class="reference internal" href="#1.-Creating-a-Keras-model-with-subclass-layers">1. Creating a Keras model with subclass layers</a></li>
<li><a class="reference internal" href="#2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers">2. Converting the Keras model with subclass layers to a Keras model with functional layers</a></li>
<li><a class="reference internal" href="#3.-Showing-similarities-and-differences-between-the-original-and-converted-models">3. Showing similarities and differences between the original and converted models</a></li>
<li><a class="reference internal" href="#4.-Discussing-the-limitations-of-the-Keras-Model-Preparer">4. Discussing the limitations of the Keras Model Preparer</a></li>
<li><a class="reference internal" href="#Summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Keras-Model-Preparer">
<h1>Keras Model Preparer<a class="headerlink" href="#Keras-Model-Preparer" title="Permalink to this headline">¶</a></h1>
<p>This notebook shows how to prepare a Keras model for quantization. Specifically, this preparer converts a Keras model with subclass layers into a Keras model with functional layers. This is required for quantization because the AIMET quantization tooling only supports the Functional and Sequantial Keras model building API’s.</p>
<p>To learn more about the Keras Model Preparer, please refer to the API Docs in AIMET.</p>
<div class="section" id="Overall-flow">
<h2>Overall flow<a class="headerlink" href="#Overall-flow" title="Permalink to this headline">¶</a></h2>
<p>This notebook covers the following 1. Creating a Keras model with subclass layers 2. Converting the Keras model with subclass layers to a Keras model with functional layers 3. Showing similarities and differences between the original and converted models 4. Dicussing the limitations of the Keras Model Preparer</p>
<hr class="docutils" />
<div class="section" id="1.-Creating-a-Keras-model-with-subclass-layers">
<h3>1. Creating a Keras model with subclass layers<a class="headerlink" href="#1.-Creating-a-Keras-model-with-subclass-layers" title="Permalink to this headline">¶</a></h3>
<p>First, we will create a Keras model with subclass layers. For this notebook example, we will use a model defined by Keras that utilizes subclass layers. This model is a text classification transformer model and can be found <a class="reference external" href="https://keras.io/examples/nlp/text_classification_with_transformer/">here</a>. The subclass layers used in this model are - <code class="docutils literal notranslate"><span class="pre">TokenAndPositionEmbedding</span></code> and <code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code>. They are defined below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import tensorflow as tf

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential(
            [tf.keras.layers.Dense(ff_dim, activation=&quot;relu&quot;), tf.keras.layers.Dense(embed_dim),]
        )
        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)

    def call(self, inputs, training, **kwargs):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)



class TokenAndPositionEmbedding(tf.keras.layers.Layer):
    def __init__(self, maxlen, vocab_size, embed_dim):
        super(TokenAndPositionEmbedding, self).__init__()
        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    def call(self, x, **kwargs):
        maxlen = tf.shape(x)[-1]
        positions = tf.range(start=0, limit=maxlen, delta=1)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        x = x + positions
        return x
</pre></div>
</div>
</div>
<p>With those subclass layers defined, we can now define the model. Since we are not training the model, we will use random weights and a random input tensor to build the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
vocab_size = 20000
maxlen = 200

random_input = np.random.random((10, 200)) # Random input to build the model

embed_dim = 32  # Embedding size for each token
num_heads = 2  # Number of attention heads
ff_dim = 32  # Hidden layer size in feed forward network inside transformer

inputs = tf.keras.layers.Input(shape=(maxlen,))
embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)
x = embedding_layer(inputs)
transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)
x = transformer_block(x)
x = tf.keras.layers.GlobalAveragePooling1D()(x)
x = tf.keras.layers.Dropout(0.1)(x)
x = tf.keras.layers.Dense(20, activation=&quot;relu&quot;)(x)
x = tf.keras.layers.Dropout(0.1)(x)
outputs = tf.keras.layers.Dense(2, activation=&quot;softmax&quot;)(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)
_ = model(random_input)
model.summary()
</pre></div>
</div>
</div>
<p>From the <code class="docutils literal notranslate"><span class="pre">model.summary()</span></code> output, we can see the models 2 subclass layers - <code class="docutils literal notranslate"><span class="pre">token_and_position_embedding</span></code>, <code class="docutils literal notranslate"><span class="pre">transformer_block</span></code>. Since these layers are using layer inside they’re classes, we need to extract them to create a symmetrical functional model.</p>
</div>
<hr class="docutils" />
<div class="section" id="2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers">
<h3>2. Converting the Keras model with subclass layers to a Keras model with functional layers<a class="headerlink" href="#2.-Converting-the-Keras-model-with-subclass-layers-to-a-Keras-model-with-functional-layers" title="Permalink to this headline">¶</a></h3>
<p>The Keras Model Preparer can be used to convert a Keras model with subclass layers to a Keras model with functional layers. The Keras Model Preparer can be imported from <code class="docutils literal notranslate"><span class="pre">aimet_tensorflow.keras.model_preparer</span></code>. The Keras Model Preparer takes in a Keras model with subclass layers and returns a Keras model with functional layers. Note that the <code class="docutils literal notranslate"><span class="pre">prepare_model</span></code> function takes an optional <code class="docutils literal notranslate"><span class="pre">input_layer</span></code> parameter. This parameter is required if the model begins with a subclass layer. In this
case, the model does not begin with a subclass layer, so we do not need to provide an <code class="docutils literal notranslate"><span class="pre">input_shape</span></code> parameter.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from aimet_tensorflow.keras.model_preparer import prepare_model

functional_model = prepare_model(model)
functional_model.summary()
</pre></div>
</div>
</div>
<p>We can see that the Keras Model Preparer has converted the model with subclass layers to a model with functional layers. Specifically, it has extracted the call function of each of these layers and created a functional layer from it.</p>
</div>
<hr class="docutils" />
<div class="section" id="3.-Showing-similarities-and-differences-between-the-original-and-converted-models">
<h3>3. Showing similarities and differences between the original and converted models<a class="headerlink" href="#3.-Showing-similarities-and-differences-between-the-original-and-converted-models" title="Permalink to this headline">¶</a></h3>
<p>We can see that the original model and the converted model are symmetrical. The only difference is that the subclass layers are unwrapped. This means that the converted model is functionally identical to the original model. We can test this in a few ways.</p>
<ol class="arabic simple">
<li><p>We can compare the total number of parameters in the original and converted models. We can see that the total number of parameters is the same.</p></li>
<li><p>We can compare the weights of the original and converted models. We can see that the weights are the same.</p>
<ul class="simple">
<li><p>Note that the order of the weights presented when calling <code class="docutils literal notranslate"><span class="pre">get_weights()</span></code> on each of these models are not the same and as is the names of the weights. We can use an internal function to get the original models weights in the same order as the converted models weights.</p></li>
</ul>
</li>
<li><p>We can compare the outputs of the original and converted models. We can see that the outputs are the same.</p></li>
</ol>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from aimet_tensorflow.keras.model_preparer import _get_original_models_weights_in_functional_model_order

assert functional_model.count_params() == model.count_params()
assert functional_model.input_shape == model.input_shape
assert functional_model.output_shape == model.output_shape

# NOTE: Since TextClassification Model has the internal layers out of order compared to the call method,
# the weights are not in the order of what the actual architecture is (this is a Keras design).
# Therefore, we get the original model&#39;s weights and sort them in the order of the actual
# architecture and use those weights to compare to the functional model&#39;s weights.
model_weights_in_correct_order = _get_original_models_weights_in_functional_model_order(
    model, functional_model, class_names=[&quot;token_and_position_embedding&quot;, &quot;transformer_block&quot;])

for i, _ in enumerate(model_weights_in_correct_order):
        np.testing.assert_array_equal(model_weights_in_correct_order[i], functional_model.get_weights()[i])

np.testing.assert_array_equal(functional_model(random_input).numpy(), model(random_input).numpy())
print(&quot;Models are equal&quot;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="4.-Discussing-the-limitations-of-the-Keras-Model-Preparer">
<h3>4. Discussing the limitations of the Keras Model Preparer<a class="headerlink" href="#4.-Discussing-the-limitations-of-the-Keras-Model-Preparer" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>The AIMET Keras ModelPreparer API is able to convert subclass layers that have arthmetic experssion in their call function. However, this API and Keras, will convert these operations to TFOPLambda layers which are not currently supported by AIMET Keras Quantization API. If possible, it is recommended to have the subclass layers call function ressemble the Keras Functional API layers. For example, if a subclass layer has two convolution layers in its call function, the call function should
look like the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</li>
<li><p>If the model starts with a subclassed layer, the AIMET Keras ModelPreparer API will need an Keras Input Layer as input. This is becuase the Keras Functional API requires an Input Layer as the first layer in the model. The AIMET Keras ModelPreparer API will raise an exception if the model starts with a subclassed layer and an Input Layer is not provided as input.</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="Summary">
<h3>Summary<a class="headerlink" href="#Summary" title="Permalink to this headline">¶</a></h3>
<p>Hopefully this notebook was useful for you to understand how to use the Keras Model Preparer.</p>
<p>Few additional resources: - <a class="reference external" href="https://quic.github.io/aimet-pages/releases/latest/user_guide/index.html">AIMET API Docs</a></p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../../../../user_guide/index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.24.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>