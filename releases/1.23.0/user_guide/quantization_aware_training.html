

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>AIMET Quantization Aware Training &#8212; AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.23.0</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.23.0</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="../_static/brain_logo.png" alt="Logo"/>
            </a></p>
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">AIMET Quantization Aware Training</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#qat-workflow">QAT workflow</a></li>
<li><a class="reference internal" href="#qat-modes">QAT modes</a></li>
</ul>
</li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="aimet-quantization-aware-training">
<h1>AIMET Quantization Aware Training<a class="headerlink" href="#aimet-quantization-aware-training" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>In cases where PTQ techniques are not sufficient for mitigating quantization error, users can use quantization-aware
training (QAT). QAT models the quantization noise during training and allows the model to find better solutions
than post-training quantization. However, the higher accuracy comes with the usual costs of neural
network training, i.e. longer training times, need for labeled data and hyperparameter search.</p>
</div>
<div class="section" id="qat-workflow">
<h2>QAT workflow<a class="headerlink" href="#qat-workflow" title="Permalink to this headline">¶</a></h2>
<p>The QAT workflow is largely similar to the flow for using Quantization Simulation for inference. The only difference is
that a user can take the sim.model and use it in their training pipeline in order to fine-tune model parameters while
taking quantization noise into account. The user’s training pipeline will not need to change in order to train the
sim.model compared to training the original model.</p>
<p>A typical pipeline is as follows:</p>
<ol class="arabic simple">
<li><p>Create a QuantSim sim object from a pretrained model.</p></li>
<li><p>Calibrate the sim using representative data samples to come up with initial encoding values for each quantizer node.</p></li>
<li><p>Pass the sim.model into a training pipeline to fine-tune the model parameters.</p></li>
<li><p>Evaluate the sim.model using an evaluation pipeline to check whether model accuracy has improved.</p></li>
<li><p>Export the sim to generate a model with updated weights and no quantization nodes, along with the accompanying
encodings file containing quantization scale/offset parameters for each quantization node.</p></li>
</ol>
<p>Observe that as compared to QuantSim inference, step 3 is the only addition when performing QAT.</p>
</div>
<div class="section" id="qat-modes">
<h2>QAT modes<a class="headerlink" href="#qat-modes" title="Permalink to this headline">¶</a></h2>
<p>There are two variants of QAT, referred to as QAT without Range Learning and QAT with Range Learning.</p>
<p>In QAT without Range Learning, encoding values for activation quantizers are found once in the beginning during the
calibration step after QuantSim has been instantiated, and are not updated again subsequently throughout training.</p>
<p>In QAT with Range Learning, encoding values for activation quantizers are initially set during the calibration step, but
are free to update during training, allowing a more optimal set of scale/offset quantization parameters to be found
as training takes place.</p>
<p>In both variants, parameter quantizer encoding values will continue to update in accordance with the parameters
themselves updating during training.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">AI Model Efficiency Toolkit Documentation: ver tf-torch-cpu_1.23.0</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Qualcomm Innovation Center, Inc..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.
    </div>
  </body>
</html>